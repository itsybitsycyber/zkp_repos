{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean `zkp_repos.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "from pydriller import Repository\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "access_token = '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'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zkp_repos.csv')\n",
    "df = df.rename({\"Tool Resources (Twitter, Discord, Website etc.)\": \"Tool Resources\"}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tools(row):\n",
    "    if row['Type'] == 'Application':\n",
    "        return row['Tool'].split(', ')\n",
    "        \n",
    "\n",
    "df['Tool'] = df.apply(split_tools, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UniqueID'] = df['URL'].apply(lambda x: '/'.join(x.split('/')[-2:][::-1]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('zkp_repos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the commit data and file changes for the 'Tool' repositories using PyDriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories =  df[df['Type'] == 'Tool'].URL.values.tolist()\n",
    "\n",
    "commit_data = []\n",
    "file_data = []\n",
    "\n",
    "for repo_url in repositories:\n",
    "    for commit in Repository(repo_url).traverse_commits():\n",
    "            \n",
    "            commit_data.append({\n",
    "                'UniqueID': f'{repo_url.split(\"/\")[-1]}/{ repo_url.split(\"/\")[-2]}',\n",
    "                'Name': repo_url.split('/')[-1],\n",
    "                'Owner': repo_url.split('/')[-2],\n",
    "                'CommitHash': commit.hash,\n",
    "                'Message': commit.msg,\n",
    "                'Author': commit.author.name,\n",
    "                'AuthorEmail': commit.author.email,\n",
    "                'Committer': commit.committer.name,\n",
    "                'CommitterEmail': commit.committer.email,\n",
    "                'AuthorDate': commit.author_date,\n",
    "                'CommitterDate': commit.committer_date,\n",
    "                'AuthorTimeZone': commit.author_timezone,\n",
    "                'CommitterTimeZone': commit.committer_timezone,\n",
    "                'Branches': commit.branches,\n",
    "                'Main': commit.in_main_branch,\n",
    "                'Merge': commit.merge,\n",
    "                'ModificationCount': len(commit.modified_files),\n",
    "                'AddedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"ADD\"],\n",
    "                'ModifiedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"MODIFY\"],\n",
    "                'DeletedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"DELETE\"],\n",
    "                'RenamedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"RENAME\"],\n",
    "                'Parents': commit.parents,\n",
    "                'Deletions': commit.deletions,\n",
    "                'Insertions': commit.insertions,\n",
    "                'Lines': commit.lines,\n",
    "                'Files': commit.files\n",
    "                })\n",
    "            for modified_file in commit.modified_files:\n",
    "                print(modified_file)\n",
    "                file_data.append({\n",
    "                    'UniqueID': f'{repo_url.split(\"/\")[-1]}/{ repo_url.split(\"/\")[-2]}',\n",
    "                    'Name': repo_url.split('/')[-1],\n",
    "                    'Owner': repo_url.split('/')[-2],\n",
    "                    'CommitHash': commit.hash,\n",
    "                    'Filename': modified_file.filename,\n",
    "                    'ChangeType': modified_file.change_type.name,\n",
    "                    'OldPath': modified_file.old_path,\n",
    "                    'NewPath': modified_file.new_path,\n",
    "                    'Diff': modified_file.diff,\n",
    "                    'DiffParser': modified_file.diff_parsed,\n",
    "                    'AddedLines': modified_file.added_lines,\n",
    "                    'DeletedLines': modified_file.deleted_lines,\n",
    "                    # 'SourceCode': modified_file.source_code,\n",
    "                    # 'SourceCodeBefore': modified_file.source_code,\n",
    "                    'Methods': modified_file.methods, \n",
    "                    'MethodsBefore': modified_file.methods_before,\n",
    "                    'ChangedMethods': modified_file.changed_methods,\n",
    "                    'nloc': modified_file.nloc,\n",
    "                    'Complexity': modified_file.complexity,\n",
    "                    'TokenCount': modified_file.token_count \n",
    "                })\n",
    "\n",
    "\n",
    "commit_df = pd.DataFrame(commit_data)\n",
    "file_df = pd.DataFrame(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_df.to_csv('tool_commits.csv')\n",
    "file_df.to_csv('tool_file_changes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting commits for https://github.com/andrewmilson/ecfft\n"
     ]
    }
   ],
   "source": [
    "def get_commit_data(repos):\n",
    "    commit_data = []\n",
    "    \n",
    "    for repo in repos:\n",
    "        print(f\"Getting commits for {repo}\")\n",
    "        for commit in Repository(repo).traverse_commits():\n",
    "                commit_data.append({\n",
    "                    'UniqueID': f'{repo.split(\"/\")[-1]}/{repo.split(\"/\")[-2]}',\n",
    "                    'Name': repo.split('/')[-1],\n",
    "                    'Owner': repo.split('/')[-2],\n",
    "                    'CommitHash': commit.hash,\n",
    "                    'Message': commit.msg,\n",
    "                    'Author': commit.author.name,\n",
    "                    'AuthorEmail': commit.author.email,\n",
    "                    'Committer': commit.committer.name,\n",
    "                    'CommitterEmail': commit.committer.email,\n",
    "                    'AuthorDate': commit.author_date,\n",
    "                    'CommitterDate': commit.committer_date,\n",
    "                    'AuthorTimeZone': commit.author_timezone,\n",
    "                    'CommitterTimeZone': commit.committer_timezone,\n",
    "                    'Branches': commit.branches,\n",
    "                    'Main': commit.in_main_branch,\n",
    "                    'Merge': commit.merge,\n",
    "                    'ModificationCount': len(commit.modified_files),\n",
    "                    'AddedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"ADD\"],\n",
    "                    'ModifiedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"MODIFY\"],\n",
    "                    'DeletedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"DELETE\"],\n",
    "                    'RenamedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"RENAME\"],\n",
    "                    'Parents': commit.parents,\n",
    "                    'Deletions': commit.deletions,\n",
    "                    'Insertions': commit.insertions,\n",
    "                    'Lines': commit.lines,\n",
    "                    'Files': commit.files\n",
    "                    })\n",
    "        commit_df = pd.DataFrame(commit_data)\n",
    "        commit_df.to_csv('application_commit_data.csv', mode='a')\n",
    "    return commit_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting commits for https://github.com/andrewmilson/ecfft\n",
      "Getting commits for https://github.com/Electron-Labs/electron-rs\n",
      "Getting commits for https://github.com/anoma/vamp-ir\n",
      "Getting commits for https://github.com/EdgarBarrantes/field-matrix\n",
      "Getting commits for https://github.com/zink-lang/zink\n",
      "Getting commits for https://github.com/crate-crypto/py-arkworks-bls12381\n",
      "Getting commits for https://github.com/achimcc/substrate-arkworks-examples\n",
      "Getting commits for https://github.com/zigtur/zk-learning.org-course\n",
      "Getting commits for https://github.com/sec-bit/ckb-zkp\n",
      "Getting commits for https://github.com/lambdaclass/aleo_lambda_vm\n"
     ]
    }
   ],
   "source": [
    "repos = df[df['Type'] == 'Application'].URL.values.tolist()\n",
    "\n",
    "t1 = threading.Thread(target=get_commit_data, args=([repos[:5]]))\n",
    "t2 = threading.Thread(target=get_commit_data, args=([repos[5:10]]))\n",
    " \n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the contributor data for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_data = []\n",
    "\n",
    "access_token = ''\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json' \n",
    "}\n",
    "\n",
    "for repo in df.URL.values.tolist():\n",
    "\n",
    "    repo_name = f\"{repo.split('/')[-2]}/{repo.split('/')[-1]}\"\n",
    "\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        url = f'https://api.github.com/repos/{repo_name}/contributors?page={page}&per_page=30'\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            contributors = response.json()\n",
    "            if len(contributors) == 0:\n",
    "                break \n",
    "            for contributor in contributors:\n",
    "                contributor_data.append({\n",
    "                    'RepositoryName': repo.split('/')[-1],\n",
    "                    'Owner': repo.split('/')[-2],\n",
    "                    'Contributor': contributor['login'],\n",
    "                    'RepoUrl': repo,\n",
    "                    'ContributorURL': contributor['url'],\n",
    "                    'Contributions': contributor['contributions'],\n",
    "                    'Type': contributor['type'],\n",
    "                    'SiteAdmin': contributor['site_admin']\n",
    "                })\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f'Failed to fetch data for {repo_name}, page {page}. Status code: {response.status_code}')\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_df = pd.DataFrame(contributor_data)\n",
    "contributor_df['RepositoryName'] = contributor_df['RepositoryName'].str.lower()\n",
    "contributor_df['Contributor'] = contributor_df['Contributor'].str.lower()\n",
    "contributor_df.to_csv('contributor_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the issue data for all repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_data = []\n",
    "\n",
    "df_tools = df[df['Type'] == 'Tool']\n",
    "repositories = df_tools['UniqueID'].tolist()\n",
    "\n",
    "\n",
    "for repo in repositories:\n",
    "    \n",
    "    page = 1\n",
    "    has_more_issues = True\n",
    "    \n",
    "    owner = repo.split(\"/\")[1]\n",
    "    repo_name =  repo.split(\"/\")[0]\n",
    "    \n",
    "    print(f\"Getting issues for {owner}/{repo_name}\")\n",
    "\n",
    "    while True:\n",
    "        issues_url = f'https://api.github.com/repos/{owner}/{repo_name}/issues?page={page}&per_page=30'\n",
    "        response = requests.get(issues_url,  headers=headers) \n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            issues = response.json()\n",
    "\n",
    "            if len(issues) == 0:\n",
    "                break\n",
    "\n",
    "            for issue in issues:\n",
    "                issues_data.append({\n",
    "                    'RepositoryName': repo_name,\n",
    "                    'Owner': owner,\n",
    "                    'URL': issue['html_url'],\n",
    "                    'ApiURL': issue['url'],\n",
    "                    'RepositoryURL': issue['repository_url'],\n",
    "                    'User': issue['user']['login'],\n",
    "                    'UserType': issue['user']['type'],\n",
    "                    'UserURL': issue['user']['html_url'],\n",
    "                    'SiteAdmin': issue['user']['site_admin'],\n",
    "                    'Labels': issue['labels'],\n",
    "                    'State': issue['state'],\n",
    "                    'Locked': issue['locked'],\n",
    "                    'Assignee': issue['assignee'],\n",
    "                    'Assignees': issue['assignees'],\n",
    "                    'Comments': issue['comments'],\n",
    "                    'CreatedAt': issue['created_at'],\n",
    "                    'ClosedAt': issue['closed_at'],\n",
    "                    'AuthorAssociation': issue['author_association'],\n",
    "                    'PullRequestURL': issue['pull_request'] if 'pull_request' in issue else None,\n",
    "                    'ReactionCount': issue['reactions']['total_count']\n",
    "                })\n",
    "        else:\n",
    "            print(f'Failed to retrieve issue data for {repo}, page {page}.  Status code {response.status_code}.')\n",
    "        \n",
    "        page += 1\n",
    "\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        issues_url = f'https://api.github.com/repos/{owner}/{repo_name}/issues?page={page}&per_page=30&state=closed'\n",
    "        response = requests.get(issues_url,  headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            issues = response.json()\n",
    "\n",
    "            if len(issues) == 0:\n",
    "                break\n",
    "\n",
    "            for issue in issues:\n",
    "                issues_data.append({\n",
    "                    'RepositoryName': repo_name,\n",
    "                    'Owner': owner,\n",
    "                    'URL': issue['html_url'],\n",
    "                    'ApiURL': issue['url'],\n",
    "                    'RepositoryURL': issue['repository_url'],\n",
    "                    'User': issue['user']['login'],\n",
    "                    'UserType': issue['user']['type'],\n",
    "                    'UserURL': issue['user']['html_url'],\n",
    "                    'SiteAdmin': issue['user']['site_admin'],\n",
    "                    'Labels': issue['labels'],\n",
    "                    'State': issue['state'],\n",
    "                    'Locked': issue['locked'],\n",
    "                    'Assignee': issue['assignee'],\n",
    "                    'Assignees': issue['assignees'],\n",
    "                    'Comments': issue['comments'],\n",
    "                    'CreatedAt': issue['created_at'],\n",
    "                    'ClosedAt': issue['closed_at'],\n",
    "                    'AuthorAssociation': issue['author_association'],\n",
    "                    'PullRequestURL': issue['pull_request'] if 'pull_request' in issue else None,\n",
    "                    'ReactionCount': issue['reactions']['total_count']\n",
    "                })\n",
    "        else:\n",
    "            print(f'Failed to retrieve issue data for {repo}, page {page}.  Status code {response.status_code}.')\n",
    "        \n",
    "        page += 1\n",
    "\n",
    "issues_df = pd.DataFrame(issues_data)\n",
    "issues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df.to_csv('tool_issues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for each contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_df = pd.read_csv('repo_contributors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_df = contributor_df[contributor_df['Contributor'] != 'dependabot[bot]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors = contributor_df['Contributor'].unique()\n",
    "contributors_data = []\n",
    "\n",
    "delay_duration = 60\n",
    "\n",
    "for contributor in contributors:     \n",
    "    success = False\n",
    "\n",
    "    while not success:\n",
    "        contibutor_url = f'https://api.github.com/users/{contributor}'\n",
    "        response = requests.get(contibutor_url,  headers=headers) \n",
    "\n",
    "        if response.status_code == 200:\n",
    "            contributor_data = response.json()\n",
    "            \n",
    "            contributors_data.append({\n",
    "                'Login': contributor_data['login'],\n",
    "                'ID': contributor_data['id'],\n",
    "                'URL': contributor_data['html_url'],\n",
    "                'Type': contributor_data['type'],\n",
    "                'SiteAdmin': contributor_data['site_admin'],\n",
    "                'Name': contributor_data['name'],\n",
    "                'Bio': contributor_data['bio'],\n",
    "                'Company': contributor_data['company'],\n",
    "                'Blog': contributor_data['blog'],\n",
    "                'Location': contributor_data['location'],\n",
    "                'Email': contributor_data['email'],\n",
    "                'Hireable': contributor_data['hireable'],\n",
    "                'Twitter': contributor_data['twitter_username'],\n",
    "                'PublicRepos': contributor_data['public_repos'],\n",
    "                'PublicGists': contributor_data['public_gists'],\n",
    "                'Followers': contributor_data['followers'],\n",
    "                'Following': contributor_data['following'],\n",
    "                'CreatedAt': contributor_data['created_at']\n",
    "            })\n",
    "\n",
    "            success = True\n",
    "        elif response.status_code == 429:\n",
    "            print(f'Rate limit exceeded. Waiting for {delay_duration} seconds...')\n",
    "            time.sleep(delay_duration)\n",
    "\n",
    "        else:\n",
    "             print(f'Failed to retrieve user data for {contributor} due to {response.status_code}. Check the username and API access.')\n",
    "             success = True\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "contributor_info_df = pd.DataFrame(contributors_data)\n",
    "contributor_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contributor_info_df.to_csv('contributor_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get branch data for tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting issues for starknet-rs/xjonathanlei\n",
      "Getting issues for plonky2/mir-protocol\n",
      "Getting issues for bellman/zkcrypto\n",
      "Getting issues for bulletproofs/sdiehl\n",
      "Getting issues for bulletproofs/dalek-cryptography\n",
      "Getting issues for cairo/starkware-libs\n",
      "Getting issues for circom/iden3\n",
      "Getting issues for circomlib/iden3\n",
      "Getting issues for gnark/consensys\n",
      "Getting issues for leo/aleohq\n",
      "Getting issues for libsnark/scipr-lab\n",
      "Getting issues for miden-vm/0xpolygonmiden\n",
      "Getting issues for noir/noir-lang\n",
      "Getting issues for openzkp/0xproject\n",
      "Getting issues for plonky/mir-protocol\n",
      "Getting issues for plonky3/plonky3\n",
      "Getting issues for pysnark/charterhouse\n",
      "Getting issues for risc0/risc0\n",
      "Getting issues for snarkjs/iden3\n",
      "Getting issues for winterfell/facebook\n",
      "Getting issues for zokrates/zokrates\n",
      "Getting issues for merlin/dalek-cryptography\n",
      "Getting issues for halo2/zcash\n",
      "Getting issues for snarky/o1-labs\n",
      "Getting issues for zksync/matter-labs\n",
      "Getting issues for algebra/arkworks-rs\n",
      "Getting issues for std/arkworks-rs\n",
      "Getting issues for curves/arkworks-rs\n",
      "Getting issues for groth16/arkworks-rs\n",
      "Getting issues for r1cs-std/arkworks-rs\n",
      "Getting issues for crypto-primitives/arkworks-rs\n",
      "Getting issues for marlin/arkworks-rs\n",
      "Getting issues for poly-commit/arkworks-rs\n",
      "Getting issues for nonnative/arkworks-rs\n",
      "Getting issues for sponge/arkworks-rs\n",
      "Getting issues for snark/arkworks-rs\n",
      "Getting issues for circom-compat/arkworks-rs\n",
      "Getting issues for gm17/arkworks-rs\n",
      "Getting issues for gemini/arkworks-rs\n",
      "Getting issues for cairo-lang/starkware-libs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RepositoryName</th>\n",
       "      <th>Owner</th>\n",
       "      <th>BranchName</th>\n",
       "      <th>CommitSHA</th>\n",
       "      <th>CommitURL</th>\n",
       "      <th>Protected</th>\n",
       "      <th>UniqueId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>starknet-rs</td>\n",
       "      <td>xjonathanlei</td>\n",
       "      <td>dev/blocking</td>\n",
       "      <td>44f8853f1f02a251f7ed961149b489fbc0c70292</td>\n",
       "      <td>https://api.github.com/repos/xJonathanLEI/star...</td>\n",
       "      <td>False</td>\n",
       "      <td>starknet-rs/xjonathanlei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starknet-rs</td>\n",
       "      <td>xjonathanlei</td>\n",
       "      <td>fix/artifact_deser</td>\n",
       "      <td>ef13316f4063fac7c53a4f6150b81a8bb710959f</td>\n",
       "      <td>https://api.github.com/repos/xJonathanLEI/star...</td>\n",
       "      <td>False</td>\n",
       "      <td>starknet-rs/xjonathanlei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starknet-rs</td>\n",
       "      <td>xjonathanlei</td>\n",
       "      <td>master</td>\n",
       "      <td>f16271877c9dbf08bc7bf61e4fc72decc13ff73d</td>\n",
       "      <td>https://api.github.com/repos/xJonathanLEI/star...</td>\n",
       "      <td>True</td>\n",
       "      <td>starknet-rs/xjonathanlei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plonky2</td>\n",
       "      <td>mir-protocol</td>\n",
       "      <td>agg_circuit</td>\n",
       "      <td>f7d13490b67bc35437905f74ea4111ce38403557</td>\n",
       "      <td>https://api.github.com/repos/mir-protocol/plon...</td>\n",
       "      <td>False</td>\n",
       "      <td>plonky2/mir-protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plonky2</td>\n",
       "      <td>mir-protocol</td>\n",
       "      <td>base_sum_gate_64</td>\n",
       "      <td>8620322faf33ab24cafb6fbacc063796bd71a018</td>\n",
       "      <td>https://api.github.com/repos/mir-protocol/plon...</td>\n",
       "      <td>False</td>\n",
       "      <td>plonky2/mir-protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>gemini</td>\n",
       "      <td>arkworks-rs</td>\n",
       "      <td>feature/fast-entry-product</td>\n",
       "      <td>c169b65cfdc71b32dcce9e6e097f6f58583cbf5d</td>\n",
       "      <td>https://api.github.com/repos/arkworks-rs/gemin...</td>\n",
       "      <td>False</td>\n",
       "      <td>gemini/arkworks-rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>gemini</td>\n",
       "      <td>arkworks-rs</td>\n",
       "      <td>feature/transparent</td>\n",
       "      <td>9b6827e4f8e688df95fcd765d22982043d3812a6</td>\n",
       "      <td>https://api.github.com/repos/arkworks-rs/gemin...</td>\n",
       "      <td>False</td>\n",
       "      <td>gemini/arkworks-rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>gemini</td>\n",
       "      <td>arkworks-rs</td>\n",
       "      <td>main</td>\n",
       "      <td>2c62479f670e2a10b68b719a0a8ba8ef57aa70ba</td>\n",
       "      <td>https://api.github.com/repos/arkworks-rs/gemin...</td>\n",
       "      <td>False</td>\n",
       "      <td>gemini/arkworks-rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>cairo-lang</td>\n",
       "      <td>starkware-libs</td>\n",
       "      <td>lior/get-future-function-pc</td>\n",
       "      <td>c25f826741a747b216d0cacb8f6a7c3207c574d8</td>\n",
       "      <td>https://api.github.com/repos/starkware-libs/ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>cairo-lang/starkware-libs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>cairo-lang</td>\n",
       "      <td>starkware-libs</td>\n",
       "      <td>master</td>\n",
       "      <td>27a157d761ae49b242026bcbe5fca6e60c1e98bd</td>\n",
       "      <td>https://api.github.com/repos/starkware-libs/ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>cairo-lang/starkware-libs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1346 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RepositoryName           Owner                   BranchName  \\\n",
       "0       starknet-rs    xjonathanlei                 dev/blocking   \n",
       "1       starknet-rs    xjonathanlei           fix/artifact_deser   \n",
       "2       starknet-rs    xjonathanlei                       master   \n",
       "3           plonky2    mir-protocol                  agg_circuit   \n",
       "4           plonky2    mir-protocol             base_sum_gate_64   \n",
       "...             ...             ...                          ...   \n",
       "1341         gemini     arkworks-rs   feature/fast-entry-product   \n",
       "1342         gemini     arkworks-rs          feature/transparent   \n",
       "1343         gemini     arkworks-rs                         main   \n",
       "1344     cairo-lang  starkware-libs  lior/get-future-function-pc   \n",
       "1345     cairo-lang  starkware-libs                       master   \n",
       "\n",
       "                                     CommitSHA  \\\n",
       "0     44f8853f1f02a251f7ed961149b489fbc0c70292   \n",
       "1     ef13316f4063fac7c53a4f6150b81a8bb710959f   \n",
       "2     f16271877c9dbf08bc7bf61e4fc72decc13ff73d   \n",
       "3     f7d13490b67bc35437905f74ea4111ce38403557   \n",
       "4     8620322faf33ab24cafb6fbacc063796bd71a018   \n",
       "...                                        ...   \n",
       "1341  c169b65cfdc71b32dcce9e6e097f6f58583cbf5d   \n",
       "1342  9b6827e4f8e688df95fcd765d22982043d3812a6   \n",
       "1343  2c62479f670e2a10b68b719a0a8ba8ef57aa70ba   \n",
       "1344  c25f826741a747b216d0cacb8f6a7c3207c574d8   \n",
       "1345  27a157d761ae49b242026bcbe5fca6e60c1e98bd   \n",
       "\n",
       "                                              CommitURL  Protected  \\\n",
       "0     https://api.github.com/repos/xJonathanLEI/star...      False   \n",
       "1     https://api.github.com/repos/xJonathanLEI/star...      False   \n",
       "2     https://api.github.com/repos/xJonathanLEI/star...       True   \n",
       "3     https://api.github.com/repos/mir-protocol/plon...      False   \n",
       "4     https://api.github.com/repos/mir-protocol/plon...      False   \n",
       "...                                                 ...        ...   \n",
       "1341  https://api.github.com/repos/arkworks-rs/gemin...      False   \n",
       "1342  https://api.github.com/repos/arkworks-rs/gemin...      False   \n",
       "1343  https://api.github.com/repos/arkworks-rs/gemin...      False   \n",
       "1344  https://api.github.com/repos/starkware-libs/ca...      False   \n",
       "1345  https://api.github.com/repos/starkware-libs/ca...      False   \n",
       "\n",
       "                       UniqueId  \n",
       "0      starknet-rs/xjonathanlei  \n",
       "1      starknet-rs/xjonathanlei  \n",
       "2      starknet-rs/xjonathanlei  \n",
       "3          plonky2/mir-protocol  \n",
       "4          plonky2/mir-protocol  \n",
       "...                         ...  \n",
       "1341         gemini/arkworks-rs  \n",
       "1342         gemini/arkworks-rs  \n",
       "1343         gemini/arkworks-rs  \n",
       "1344  cairo-lang/starkware-libs  \n",
       "1345  cairo-lang/starkware-libs  \n",
       "\n",
       "[1346 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = df[df['Type'] == 'Tool']['UniqueID']\n",
    "\n",
    "branches_data = []\n",
    "\n",
    "for tool in tools: \n",
    "    page = 1\n",
    "    has_more_branches = True\n",
    "\n",
    "    owner = tool.split(\"/\")[1]\n",
    "    repo_name =  tool.split(\"/\")[0]\n",
    "    \n",
    "    print(f\"Getting issues for {tool}\")\n",
    "\n",
    "    while True:\n",
    "        branches_url = f'https://api.github.com/repos/{owner}/{repo_name}/branches?page={page}&per_page=30'\n",
    "        response = requests.get(branches_url,  headers=headers) \n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            branches = response.json()\n",
    "\n",
    "            if len(branches) == 0:\n",
    "                break\n",
    "\n",
    "            for branch in branches:\n",
    "                branches_data.append({\n",
    "                    'RepositoryName': repo_name,\n",
    "                    'Owner': owner,\n",
    "                    'BranchName': branch['name'],\n",
    "                    'CommitSHA': branch['commit']['sha'],\n",
    "                    'CommitURL': branch['commit']['url'],\n",
    "                    'Protected': branch['protected'],\n",
    "                    'UniqueID': tool\n",
    "                })\n",
    "        else:\n",
    "            print(f'Failed to retrieve branche data for {repo}, page {page}.  Status code {response.status_code}.')\n",
    "        \n",
    "        page += 1\n",
    "    \n",
    "branches_df = pd.DataFrame(branches_data)\n",
    "branches_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_df.to_csv('branches_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
