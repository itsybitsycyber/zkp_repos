{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean `zkp_repos.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pydriller import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zkp_repos.csv', sep=';')\n",
    "df = df.rename({\"Tool Resources (Twitter, Discord, Website etc.)\": \"Tool Resources\"}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tools(row):\n",
    "    if row['Type'] == 'Application':\n",
    "        return row['Tool'].split(', ')\n",
    "        \n",
    "\n",
    "df['Tool'] = df.apply(split_tools, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('zkp_repos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the commit data and file changes for the 'Tool' repositories using PyDriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories =  df[df['Type'] == 'Tool'].URL.values.tolist()\n",
    "\n",
    "commit_data = []\n",
    "file_data = []\n",
    "\n",
    "for repo_url in repositories:\n",
    "    for commit in Repository(repo_url).traverse_commits():\n",
    "            \n",
    "            commit_data.append({\n",
    "                'Name': repo_url.split('/')[-1],\n",
    "                'Owner': repo_url.split('/')[-2],\n",
    "                'CommitHash': commit.hash,\n",
    "                'Message': commit.msg,\n",
    "                'Author': commit.author.name,\n",
    "                'AuthorEmail': commit.author.email,\n",
    "                'Committer': commit.committer.name,\n",
    "                'CommitterEmail': commit.committer.email,\n",
    "                'AuthorDate': commit.author_date,\n",
    "                'CommitterDate': commit.committer_date,\n",
    "                'AuthorTimeZone': commit.author_timezone,\n",
    "                'CommitterTimeZone': commit.committer_timezone,\n",
    "                'Branches': commit.branches,\n",
    "                'Main': commit.in_main_branch,\n",
    "                'Merge': commit.merge,\n",
    "                'ModificationCount': len(commit.modified_files),\n",
    "                'AddedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"ADD\"],\n",
    "                'ModifiedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"MODIFY\"],\n",
    "                'DeletedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"DELETE\"],\n",
    "                'RenamedFiles': [modification.filename for modification in commit.modified_files if modification.change_type.name == \"RENAME\"],\n",
    "                'Parents': commit.parents,\n",
    "                'Deletions': commit.deletions,\n",
    "                'Insertions': commit.insertions,\n",
    "                'Lines': commit.lines,\n",
    "                'Files': commit.files})\n",
    "            for modified_file in commit.modified_files:\n",
    "                print(modified_file)\n",
    "                file_data.append({\n",
    "                    'Name': repo_url.split('/')[-1],\n",
    "                    'Owner': repo_url.split('/')[-2],\n",
    "                    'CommitHash': commit.hash,\n",
    "                    'Filename': modified_file.filename,\n",
    "                    'ChangeType': modified_file.change_type.name,\n",
    "                    'OldPath': modified_file.old_path,\n",
    "                    'NewPath': modified_file.new_path,\n",
    "                    'Diff': modified_file.diff,\n",
    "                    'DiffParser': modified_file.diff_parsed,\n",
    "                    'AddedLines': modified_file.added_lines,\n",
    "                    'DeletedLines': modified_file.deleted_lines,\n",
    "                    # 'SourceCode': modified_file.source_code,\n",
    "                    # 'SourceCodeBefore': modified_file.source_code,\n",
    "                    'Methods': modified_file.methods, \n",
    "                    'MethodsBefore': modified_file.methods_before,\n",
    "                    'ChangedMethods': modified_file.changed_methods,\n",
    "                    'nloc': modified_file.nloc,\n",
    "                    'Complexity': modified_file.complexity,\n",
    "                    'TokenCount': modified_file.token_count \n",
    "                })\n",
    "\n",
    "\n",
    "commit_df = pd.DataFrame(commit_data)\n",
    "file_df = pd.DataFrame(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_df.to_csv('tool_commits.csv')\n",
    "file_df.to_csv('tool_file_changes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the contributor data for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_data = []\n",
    "\n",
    "access_token = ''\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json' \n",
    "}\n",
    "\n",
    "for repo in df.URL.values.tolist():\n",
    "\n",
    "    repo_name = f\"{repo.split('/')[-2]}/{repo.split('/')[-1]}\"\n",
    "\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        url = f'https://api.github.com/repos/{repo_name}/contributors?page={page}&per_page=30'\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            contributors = response.json()\n",
    "            if len(contributors) == 0:\n",
    "                break \n",
    "            for contributor in contributors:\n",
    "                contributor_data.append({\n",
    "                    'RepositoryName': repo.split('/')[-1],\n",
    "                    'Owner': repo.split('/')[-2],\n",
    "                    'Contributor': contributor['login'],\n",
    "                    'RepoUrl': repo,\n",
    "                    'ContributorURL': contributor['url'],\n",
    "                    'Contributions': contributor['contributions'],\n",
    "                    'Type': contributor['type'],\n",
    "                    'SiteAdmin': contributor['site_admin']\n",
    "                })\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f'Failed to fetch data for {repo_name}, page {page}. Status code: {response.status_code}')\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor_df = pd.DataFrame(contributor_data)\n",
    "contributor_df['RepositoryName'] = contributor_df['RepositoryName'].str.lower()\n",
    "contributor_df['Contributor'] = contributor_df['Contributor'].str.lower()\n",
    "contributor_df.to_csv('contributor_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
